apiVersion: v1
kind: Secret
data:
  minio-access-key: YWRtaW4xMjM=
  minio-secret-key: bmltZGExMjM=
metadata:
  name: minio-secret
type: Opaque
---
apiVersion: apps/v1beta1
kind: StatefulSet
metadata:
  # This name uniquely identifies the StatefulSet
  name: minio
spec:
  serviceName: minio
  replicas: 4
  selector:
    matchLabels:
      app: minio # has to match .spec.template.metadata.labels
  template:
    metadata:
      labels:
        app: minio # has to match .spec.selector.matchLabels
    spec:
      containers:
      - name: minio
        env:
        - name: MINIO_ACCESS_KEY
          valueFrom:
            secretKeyRef:
              name: minio-secret
              key: minio-access-key
        - name: MINIO_SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: minio-secret
              key: minio-secret-key      
#        - name: MINIO_ACCESS_KEY
#          value: "minio"
#        - name: MINIO_SECRET_KEY
#          value: "minio123"
        image: minio/minio:latest
        args:
        - server
        - http://minio-0.minio.default.svc.cluster.local/data
        - http://minio-1.minio.default.svc.cluster.local/data
        - http://minio-2.minio.default.svc.cluster.local/data
        - http://minio-3.minio.default.svc.cluster.local/data
        ports:
        - containerPort: 9000
        # These volume mounts are persistent. Each pod in the PetSet
        # gets a volume mounted based on this field.
        volumeMounts:
        - name: data
          mountPath: /data
        # Liveness probe detects situations where Minio server instance
        # is not working properly and needs restart. Kubernetes automatically
        # restarts the pods if liveness checks fail.
        livenessProbe:
          httpGet:
            path: /minio/health/live
            port: 9000
          initialDelaySeconds: 120
          periodSeconds: 20
  # These are converted to volume claims by the controller
  # and mounted at the paths mentioned above.
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 10Gi
---
apiVersion: v1
kind: Service
metadata:
  name: minio
  labels:
    app: minio
spec:
  clusterIP: None
  ports:
    - port: 9000
      name: minio
  selector:
    app: minio
---
apiVersion: v1
kind: Service
metadata:
#  annotations:
#    traefik.backend: minio-server
#    traefik.docker.network: b2c-minio_hybris
#    traefik.enable: "true"
#    traefik.frontend.headers.SSLRedirect: "true"
#    traefik.frontend.headers.SSLTemporaryRedirect: "true"
#    traefik.frontend.redirect.entryPoint: https
#    traefik.frontend.rule: Host:minio.local
#    traefik.port: "9000"
#    traefik.protocol: http
  labels:
    app: minio
  name: minio-service
spec:
  type: ClusterIP
  ports:
  - name: minio-service
    port: 9000
    targetPort: 9000
    protocol: TCP
  selector:
    app: minio
---
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  annotations:
    kubernetes.io/ingress.class: traefik
#    traefik.ingress.kubernetes.io/frontend-entry-points: http,https
#    traefik.ingress.kubernetes.io/redirect-entry-point: https
#    traefik.ingress.kubernetes.io/redirect-permanent: "true"
  name: minio-dashboard
spec:
  rules:
  - host: minio-dashboard.local
    http:
      paths:
      - path: /
        backend:
          serviceName: minio-service
          servicePort: 9000
#  tls:
#  - secretName: prometheus-dashboard-ssl